# Fetal ECG Extraction on Time-Frequency Domain using Pix2Pix GAN

This repository contains code and data for implementing a method to extract fetal electrocardiogram (ECG) signals from a maternal ECG signal on the time-frequency domain using Pix2Pix GAN.

## 1 Background

Fetal ECG extraction from maternal ECG signals is important in clinical settings, as it can provide crucial information about fetal health. However, fetal ECG signals are typically much weaker than maternal ECG signals, making it challenging to extract them directly from the raw signal. 

## 2 Method

In this repository, we present a method for fetal ECG extraction on the time-frequency domain using Pix2Pix GAN. We train Pix2Pix to learn the mapping between maternal ECG spectrograms (domain A) and corresponding fetal ECG spectrograms (domain B). During testing, we apply the trained Pix2Pix to a maternal ECG spectrogram to obtain the corresponding fetal ECG spectrogram.

## 3 Running instructions

### 3.1 Getting started

#### Create virtual environment

First, create a virtual environment for the repository
```bash
conda create -n fecg python=3.8
```
then activate the environment 
```bash
conda activate fecg
```


#### Clone the repository

Download or clone the repository:

```bash
git clone https://github.com/dustin-nguyen-qil/fECG_cGAN.git
```
Next, install the dependencies by running
...
```bash
pip install -r requirements.txt
```

### Evaluation results

If you want to see the results without retraining the model, refer to `evaluate.ipynb` to directly see the comparison with conventional method.

If you want to run the code cells again, download the fECG spectrograms produced by conventional method and our proposed model trained with 125 epochs from [here](https://uofh-my.sharepoint.com/:u:/g/personal/dnguy222_cougarnet_uh_edu/EcDODw1IZs1MgLgKkPdBt-sBuIzFAW5byJf3_U9yfDG9aw?e=PGjyJY). 
Then unzip and put `results` folder at the outermost level in the code folder.

```
results
---> fecg_p2p
    ---> spectrogram_conventional
    ---> test_latest
```

### 3.2 Data Preparation

#### Dataset 
- Download the spectrograms generated from Abdominal and Direct dataset from [here](https://uofh-my.sharepoint.com/:u:/g/personal/dnguy222_cougarnet_uh_edu/EftKBDNDgtlCmx4PClYJcogB42zOuQZOmCdeH9F2rOd_Ug?e=wgu81y).
- Unzip the data, put into folder `data` as following
```
data
---> adbecg
---> ...
```

Pix2Pix requires to align the data for pairs of training images 
```bash
$ python datasets/combine_A_and_B.py --fold_A data/adbecg/spectrogram/A --fold_B data/adbecg/spectrogram/A --fold_AB datasets/adbecg
```

### 3.3 Training Pix2Pix

Run the following command for training (here I set `--n_epochs 5` and `--n_epochs_decay 5` to save training time if you only want to validate the training phase works fine)

```bash
python train.py --dataroot ./datasets/adbecg --name fecg_p2p --model pix2pix --direction AtoB --n_epochs 5 --n_epochs_decay 5
```

Training results will be saved in `checkpoints`. To see more intermediate results, check out `./checkpoints/fecg_p2p/web/index.html`

### 3.3 Testing Pix2Pix

If you have download the results from [here](https://uofh-my.sharepoint.com/:u:/g/personal/dnguy222_cougarnet_uh_edu/EQZSXMIzfVlLutkZv6Q-RU4BLb7ZB7Eb2OnLcoZTHAqonQ?e=L1cInh), make sure you remove the results folder before running testing.

Run the following command for testing

```bash
python test.py --dataroot ./datasets/adbecg --name fecg_p2p --model pix2pix --direction AtoB
```

The test results will be saved to a html file here: `./results/fecg_p2p/test_latest/index.html`.

### 3.4 Evaluation 

After you have run testing, you will see the results folder is automatically created. You can download the fECG spectrograms generated by conventional method from [here](https://uofh-my.sharepoint.com/:u:/g/personal/dnguy222_cougarnet_uh_edu/EQ2o2injDp9BjFag7zLFeoMB76fMKRBU3bFRsY85vkhi-Q?e=GANb51)

Then unzip and put `conventional` folder in `results` as following.

```
results
---> fecg_p2p
    ---> conventional
    ---> test_latest
```

## Acknowledgement

This repository was based on the following repository: [Pix2PixGAN](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix). We would like to thank the authors for a contributing work.

